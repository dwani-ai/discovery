services:
  app:
    image: dwani/discovery_server:latest
    ports:
      - "18889:18889"
    environment:
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONUNBUFFERED=1
      - DWANI_API_BASE_URL=host.docker.internal
    volumes:
      - app-data:/data
    networks:
      - app-network

  llama:
    image: ghcr.io/ggerganov/llama.cpp:server-cuda
    ports:
      - "9000:9000"
    environment:
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - llama-data:/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    networks:
      - app-network

volumes:
  app-data:
  llama-data:

networks:
  app-network:
    driver: bridge