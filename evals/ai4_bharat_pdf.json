{
  "response": "## Key Points of the AI4BHARAT Initiative:\n\n**Core Mission & Impact:**\n\n* **Democratizing AI for India:** AI4Bharat aims to develop open-source AI solutions for all 22 officially recognized languages of India, ensuring digital inclusion and accessibility for all citizens.\n* **Beyond Translation:** The initiative’s impact extends beyond translation to areas like education, finance, healthcare, and governance.\n* **Addressing a Data Gap:**  Recognized the critical lack of digitized data for Indian languages and proactively built datasets from the ground up.\n\n**Key Strategies & Components:**\n\n* **Open-Source Commitment:** All data and AI tools are made freely available, fostering innovation and wider adoption.\n* **Four Pillars of Success:**\n    * **Data Collection at Scale:** Extensive, geographically diverse data collection, capturing dialects and natural speech patterns.\n    * **Industrial-Scale Model Building:** Development of translation capabilities between all Indian languages + English (253 language pairs).\n    * **AI4X Stack:**  A robust technological infrastructure powering AI4Bharat and Bhashini, enabling seamless integration and scalability.\n    * **Usage at Scale:**  Achieving significant usage through the Bhashini platform (306M+ inferences, 342 organizations using it).\n* **Innovative Data Collection:** Combined mined data with manually collected data, focusing on authenticity, diversity, and cultural relevance.\n* **Community Engagement:**  Collaborated with universities, NGOs, language experts, and local communities to ensure data quality and inclusivity.\n\n**Government Support & Role of MeitY:**\n\n* **Strategic Investment:** The Ministry of Electronics and Information Technology (MeitY) played a crucial role by recognizing language technology as critical national infrastructure.\n* **Visionary Leadership:** MeitY championed open-source development and equal attention to all languages, positioning language AI as public infrastructure.\n\n**Real-World Applications & Impact:**\n\n* **Bhashini Platform:**  Provides real-time language translation and speech recognition for various sectors.\n* **Supreme Court SUVAS:** Translates legal judgments into regional languages, increasing legal accessibility.\n* **ALL & AXL (Education):** AI-powered learning tools for literacy and numeracy in vernacular languages.\n* **Kisan e-Mitra:** AI chatbot providing agricultural information to farmers in their native languages.\n* **Voice-Enabled UPI:**  Making digital payments accessible to a wider population.\n* **e-Jaadui Pitara:** AI-driven interactive learning app for young children.\n\n**Future Outlook:**\n\n* **Focus on Accessibility & Inclusion:** Expanding AI solutions to underserved communities.\n* **Integration with Digital Public Infrastructure:** Leveraging existing infrastructure (Aadhaar, UPI) to scale AI-powered services.\n* **Continued Investment & Ethical Deployment:**  Prioritizing responsible data collection and public good.\n* **Global Template:**  Adapting the AI4Bharat model for other multilingual nations.\n\n\n\nIn essence, AI4Bharat is a pioneering initiative demonstrating how open-source AI, combined with strong government support and community engagement, can drive digital inclusion and empower citizens in a linguistically diverse nation.",
  "extracted_text": {
    "0": "AI4BHARAT\nArchitecting Open-Source AI\nfor India’s 22 Official\nLanguages and Beyond",
    "1": "If developed correctly, this AI could support not just legal translations but also education, finance, healthcare, and governance, ensuring that millions of non-English speakers could fully participate in India’s digital future.\n\nAt IIT Madras, researchers Mitesh Khapra, Pratyush Kumar, and Vivek Raghavan took on the problem. They began by focusing on machine translation and speech recognition, but quickly ran into a fundamental issue —the data simply did not exist.\n\nUnlike English, which had decades of digitized text and speech available for training AI models, Indian languages had limited, fragmented, and inconsistent datasets\n\nFaced with this reality, the team made a decisive choice: if the data didn’t exist, they would build it from the ground up. The project expanded beyond research labs and into communities across the country, collecting speech and text data from speakers of underrepresented languages and dialects.\n\n“A lot of AI solutions were getting to a point where they were directly deployable on the ground and could actually be used to make a social impact. But to get these benefits, people had to choose—should they stick to their regional language, or should they shift to English to access technology? That shouldn’t be a trade-off.\n\nIf we want AI-driven services like voice-based payments or quality education to reach everyone, they must work in regional languages.\"\n\n– Mitesh Khapra, Head of AI4Bharat",
    "2": "Universities, NGOs, and language experts joined the effort, ensuring that the datasets captured not just textbook-perfect translations, but real-world speech — including dialectal variations, informal language, and the way people naturally mix languages in conversation.\n\nAs the initiative grew, the team made another bold decision: everything would be open-source. Instead of restricting access to proprietary models, they committed to making the data and AI tools freely available.\n\nThis approach turned AI4Bharat from a research project into a national AI accessibility mandate: develop comprehensive, open-source solutions for all 22 constitutionally recognized languages, positioning language technology alongside crucial national infrastructure like UPI and Aadhaar.",
    "3": "MEITY’S ROLE IN SCALING\nAI FOR ALL\nThe Ministry of Electronics and Information Technology (MeitY) has fundamentally reshaped India’s approach to language technology through a significant investment in digital infrastructure.\n\nMeitY’s foresight in recognizing language technology as critical national infrastructure has proven sustainable. While global discussions about AI were still emerging, the Ministry had already laid the groundwork for what would become one of the world’s most ambitious language technology initiatives.\n\nBy championing open-source development and ensuring equal attention to all constitutionally recognized languages, MeitY demonstrated remarkable vision in treating language AI not as a commercial product, but as essential public infrastructure. This approach, which predated similar initiatives in many developed nations, has positioned India as a pioneer in democratic, inclusive AI development\n\n“A farmer used to run in circles just to find out when his subsidy payment was coming. Now, he asks a chatbot answer, and moves on with his day. That’s what real impact looks like—not just innovation for the sake of it, but technology that actually makes daily life easier for the people who need it most.\"\n\n– Amitabh Nag, CEO of Digital India Bhashini Division",
    "4": "The impact of this approach is already visible in the comprehensive datasets available across official languages, the growing ecosystem of developers, and the emergence of Indian-language AI models that excel at local tasks.\n\nBy institutionalizing open technology in public programs and policy frameworks, MeitY has created sustainable digital infrastructure that advances both technological capabilities and social inclusion—demonstrating how thoughtful government policy can drive innovation while ensuring its benefits reach all citizens.\n\nThis strategic choice delivers practical benefits across society:\n\n* State governments can implement local language services without licensing fees\n* Researchers and universities gain access to high-quality datasets\n* Startups can build innovative solutions for sectors like agriculture, education, and healthcare\n* Communities receive contextually relevant and accessible technology",
    "5": "THE FOUR PILLARS OF INDIA’S\nLANGUAGE AI REVOLUTION\nAI4Bharat’s success rests on four key components working together: comprehensive data collection, systematic model building, robust technological infrastructure, and practical applications.\n\nWhile each component addresses specific challenges in language technology, their integration creates an effective ecosystem for serving India’s diverse linguistic needs.\n\nPillar 1: Data Collection at Scale\nThe data collection effort behind AI4Bharat represents one of the most extensive linguistic data collection projects in India’s history. The sheer geographical spread is staggering, covering hundreds of districts across all states and union territories.\n\nThe team meticulously ensured representation across rural and urban settings, different socioeconomic backgrounds, age groups, and dialectal variations.\n\nIn many cases, field teams spent weeks in a single location, building trust and gathering authentic speech samples that captured the true diversity of Indian languages.\n\nDespite this collection effort not captured linguistic data but preserved endangered dialects and speech patterns that might otherwise be lost to time.",
    "10": "Pillar 2:\nIndustrial-Scale Model Building\n\nUnder Professor Mitesh Khapra’s leadership, AI4Bharat has established a model-building infrastructure that operates at an industrial scale unmatched by any other academic institution in India.\n\nThis foundation has enabled the development of translation capabilities between all possible pairs of India’s 22 constitutionally recognized languages plus English, supporting 253 distinct language pairs for comprehensive cross-linguistic communication.\n\nThe models are architected to support complex workflows where, for example, a speaker of Assamese can converse naturally with a Telugu speaker, with AI handling the speech recognition, translation, and text-to-speech conversion in real-time.\n\nEach model undergoes rigorous training, validation, and optimization cycles — a process requiring significant computational resources and specialized expertise. The team has pioneered techniques to reduce model size while maintaining accuracy, making deployment practical even in resource-constrained environments.\n\nThis industrial approach to AI development has established new benchmarks for what’s possible in Indian language technology.",
    "11": "Pillar 3:\nThe AI4X Stack\n\nPerhaps the least visible but most crucial component of this ecosystem is the AI4X Stack — the technological infrastructure that powers both AI4Bharat and Bhashini. Developed through collaboration between the AI4Bharat lab and EkStep Foundation, this stack provides the foundation upon which all models and services operate.\n\nThe stack enables seamless integration of diverse models, manages the complex workflows between them, and provides the scalable infrastructure necessary for high-volume, real-time language processing.\n\nCurrently, this stack continues to power Bhashini’s services, while the Center for Open Software Systems (COSS) is implementing version 2, which promises even greater capabilities and efficiency.\n\nThe development of this stack represents a significant technological achievement that deserves recognition alongside the more visible models and applications.",
    "12": "Pillar 4:\nUsage at Scale\n\nThe ultimate measure of AI4Bharat’s success is in its usage and adoption. The Bhashini platform, which uses AI4Bharat’s models and stack, has achieved remarkable scale:\n\nOver 306 million total inferences\nMore than 10 million average inferences per day\n342 organizations using the platform\n36 distinct services available for integration\n\nThe platform currently hosts more than 300 AI-based language models spanning Automatic Speech Recognition (ASR), Machine Translation (MT), Text to Speech (TTS), Transliteration, and Textual Language Detection.\n\nThe service leaderboard data reveals the predominance of translation (202 million) and transliteration (103 million) services, highlighting the critical need for cross-language communication tools. These numbers reflect real-world usage by citizens, businesses, and government agencies.\n\nOrchestrating this ecosystem required significant effort from both AI4Bharat and EkStep Foundation. The establishment of a comprehensive leaderboard system enables transparent tracking of model performance and usage, fostering healthy competition and continuous improvement.\n\nEach use case represents a story of impact. From enabling farmers to access agricultural information in their native language to helping small businesses reach customers across linguistic boundaries, these models are transforming how Indians interact with technology and each other.",
    "13": "INNOVATIVE DATA\nCOLLECTION STRATEGIES\n\nCreating AI models for India’s diverse languages was both a technical challenge and a data challenge. Unlike English, which has a vast pool of digitized text and speech available for training AI models, most Indian languages lack structured, high-quality datasets.\n\nAI4Bharat had to build these datasets from scratch, balancing scale, diversity, and authenticity while ensuring inclusivity from the ground up. With 22 officially recognized languages and numerous dialects, ensuring that AI models were trained on representative, high-quality datasets required a careful balance of efficiency, cost, and accuracy.\n\nA small number of dominant languages, such as Hindi, Bengali, and Telugu, had relatively more digital presence, while others like Manipuri, Bodo, and Santali, had almost no structured data available.\n\nKashmiri\n\n22 Officially Recognised\nLanguages of India\n\nDogri\n\nPunjabi\n\nNepali Assamese\n\nSindhi\n\nMaithali Bodo Manipuri\n\nGujarati\n\nHindi\n\nBengali\n\nSanskrit\n\nSantali\n\nUrdu\n\nMarathi\n\nOriya\n\nKonkani\n\nKannada\n\nTamil\n\nMalayalam",
    "14": "To address this, the team had to rethink traditional data collection strategies to find the right mix — balancing scale, diversity, and authenticity while making the process economically viable.\n\nThis led to a multi-pronged approach that combined technology-driven solutions, community engagement, and carefully designed workflows to collect, validate, and refine datasets efficiently.\n\nAI4Bharat tackled data collection through two primary methods:\n\nMined data\nExtracted from publicly available sources such as Wikipedia, open-access government documents, and news archives like All India Radio.\n\nManually collected data\nSpeech and text data gathered directly from the field across various regions, ensuring dialectal and contextual diversity.",
    "16": "SCALING DATA COLLECTION\n\nDeveloping AI for India’s diverse languages required a structured and large-scale data collection effort across speech recognition, machine translation, and text-to-speech technologies.\n\n1. Custom Data Collection Tools\nOne of the first steps was developing tools that could manage large-scale data collection and validation while maintaining quality control. Off-the-shelf solutions were not designed specifically for managing large-scale Indian language datasets, and the team built and adapted their own.\n\nShoonya: Open-source translation and annotation platform\nTo handle text data annotation at scale, the team built Shoonya, a platform designed specifically for managing large-scale Indian language datasets. It provided:\n\n* A maker-checker-superchecker system that ensured multiple layers of review, improving quality.\n* Automated transliteration support, enabling simplified data entry across languages with complex scripts.\n* Cross-lingual references, allowing annotators to compare translations across multiple languages to improve consistency.\n* Segmentation and transcription workflows, making it easier to process speech data for AI model training.\n\nKarya App: Speech data collection at scale\nFor speech data collection, the team modified the Karya app to handle the vast linguistic diversity of India. The improvements included:\n\n* On-site validation of recorded audio to ensure quality before submission.\n* Real-time demographic tracking, allowing better representation of speakers across age, gender, and region.",
    "18": "By the Numbers:\nThe Scale of India’s Language Data Collection\n7 Speech recognition (ASR):\nOver\n144\nDistricts\n7 Machine translation (MT):\n174\n126M\n783,000 Sentence Pairs\n1893\nMined Data\nField workers\nTranslation team:\n12,000\nhours of Audio\n22\n17\ncheckers\nsuper\ncheckers\n4,800\nhours fully transcribed\nDataset sources:\n7 Text-to-Speech (TTS):\n139,000\nSentence Pairs\n1,700\n644,000\nSentence Pairs\n20 hours of male speech + 20 hours\nof female speech per language\nDaily-use language\nWikipedia content",
    "19": "A Verified Dataset for AI Development\nThis structured data collection effort has resulted in one of the most extensive and reliable datasets for Indian language AI, providing a strong foundation for speech recognition, machine translation, and text-to-speech models.\nThe multi-layer verification process ensured accuracy, inclusivity, and adaptability, supporting AI-driven applications in governance, accessibility, and digital services.\nThe team took a unique approach to ensure that inclusivity was built into the design, not added as an afterthought.\n\nKey steps to ensuring inclusion\nDialects and regional variations:\nAccounted for the natural differences in spoken vs. written language, so AI models could handle everyday conversations as well as formal text.\nCode-mixing support\nTrained AI models to understand the way Indian speakers naturally blend English with their regional language in speech and writing.\nCultural context awareness\nEnsured that translations weren’t just word-for-word accurate but culturally relevant, preventing misinterpretations.",
    "20": "THE PEOPLE BEHIND INDIA’S\nAI LANGUAGE MODELS\nBuilding AI for India’s languages was never solely about gathering data — it meant working with people across the country to record how language is actually spoken. The goal was to create models that reflected everyday speech, not just formal textbook versions.\nAchieving this required a massive field effort, where local knowledge, cultural awareness, and adaptability shaped every decision.\nBringing Language to Life in the Field\nRecording speech data at scale meant navigating different accents, dialects, and ways of speaking. In many places, language blended naturally with cultural identity, and ensuring that AI models captured this meant working closely with people who spoke them.\n\n\nIn Jammu, senior citizens became some of the most committed participants. They saw this as a way to preserve Dogri, a language they feared was losing ground to Hindi and English. Many spoke in proverbs and folk stories, ensuring the dataset carried the richness of their heritage.",
    "21": "In Bodoland, early efforts to collect data faced skepticism. Many people were wary of digital recordings and reluctant to share their voices. It took weeks of discussions with community leaders before people felt comfortable participating.\nIn Kalimpong, field teams tailored their approach to reflect the linguistic reality of the region. While West Bengal is officially a Bengali-speaking state, Nepali is the dominant language in districts like Kalimpong. This reinforced the importance of designing AI models based on real-world language use rather than relying solely on census classifications.\nEven geography and climate shaped the process. In Kashmir, heavy snowfall meant there was only a short window for data collection before roads became inaccessible.\nIn rural West Bengal, extreme heat led to midday pauses, as people avoided speaking for long periods in the summer months. Every region required a different approach, and no single method worked everywhere.\n\n“When you transcend the language barrier, you’re not just enabling the last mile, ensuring governance and service delivery actually work for every citizen.\"\n\nAmitabh Nag, CEO of Digital India Bhashini Division",
    "22": "Recording Language Diversity Across Regions\nEarly recordings revealed a key challenge — AI models were learning formal, textbook-style language that didn’t reflect how people actually spoke. Responses often sounded stiff and structured, rather than the fluid, natural conversations people have in daily life.\nTo address this, the team developed a diverse set of 2,500 questions designed to engage and ensure the collected speech data was both natural and culturally relevant.\nThese questions spanned a broad range of relatable topics, covering both state- and district-specific cultural elements. For instance, a Kashmiri participant might be asked about shikaras, while a Bodo speaker would discuss Bathou religion.\nAsking someone to say “train ticket” might have made sense in theory, but in real conversations, people said “reservation confirm hua?”. Hindi in Uttar Pradesh sounded different from Hindi in Bihar, and even within a single state, dialects varied between villages.\nThis approach helped ensure that AI models learned from real-world speech patterns rather than overly standardized or formal responses. By grounding data collection in familiar, locally relevant topics, the team captured the true diversity of Indian languages as they are spoken in everyday life.\n\n“I envision a day where people who have no idea about technology use it like an appliance, just like turning a doorknob, without understanding the depth of AI behind it. That will open new skill development, employment, and prosperity for millions.”\n\nJagadish Babu, COO, EkStep Foundation",
    "23": "The Human Effort Behind the Data\nSpeech models are as good as the data that goes into them. This meant not only collecting lessons from this effort was that technology alone doesn’t solve problems—people do. No off-the-shelf AI model could have accounted for the complexities of real-world Indian speech. Every region, every dialect, and every participant added something new to the dataset.\nTranslators had to rethink how they approached their work. Word-for-word translation didn’t always work, especially in cases where people naturally mixed English with their native language. “The AI had to learn the way people actually speak, not just what’s in a grammar book,” one translator explained.\nAV Engineers dealt with constant background noise — fans, traffic, market sounds, and street vendors calling out in the audio without making it sound artificial was a challenge. Cleaning up the audio\nVoiceover artists played a key role in text-to-speech models. All needed not just clear pronunciation but natural-sounding speech. “It’s not enough to just read a sentence correctly,” one voice artist said. “If it doesn’t sound right, the AI will always feel off.”\nProject managers and coordinators had to adjust data collection methods based on what was actually working. When they saw that people were hesitant to speak freely, they created role-play scenarios and adjusted the prompts to make responses feel more natural.",
    "24": "How Local Communities Shaped AI Training Data\nOne of the biggest lessons from this effort was that technology alone doesn’t solve problems—people do. No off-the-shelf AI model could have accounted for the complexities of real-world Indian speech. Every region, every dialect, and every participant added something new to the dataset.\nThis work also highlighted the different ways people interact with language. In cities, many participants saw AI as a way to improve customer service, banking, and other digital services. In rural areas, people spoke about how they wanted their children to be able to use technology in their own language, not just in English.\nAI4Bharat’s datasets reflect real voices, real conversations, and real cultural contexts. Every person who contributed helped shape an AI that can better understand and serve India’s linguistic diversity.",
    "25": "ACROSS 400 DISTRICTS,\nINDIA’S LANGUAGES CAME\nALIVE THROUGH ITS PEOPLE.",
    "26": "Applications of the AI4Bharat Dataset\nAI4Bharat is actively reshaping how millions of Indians engage with digital\nservices in their native languages. By embedding AI-powered solutions into\ngovernance, education, agriculture, finance, and legal accessibility, AI4Bharat is\nproving that language AI is a present-day reality.\nBhashini\nBhashini is a national initiative powered by AI4Bharat’s models, redefining how\nIndia’s digital services reach non-English speakers. By seamlessly integrating AI-\npowered voice and text translation into multiple public and private sector\napplications, Bhashini ensures barrier-free digital access for millions of Indians.\nCurrent implementation: Bhashini enables real-time language translation and\nspeech recognition across 22 scheduled Indian languages, directly benefiting\nsectors such as agriculture, healthcare, retail, governance, and legal services.\nImpact: By embedding AI-powered voice interfaces into government and financial\nservices, Bhashini ensures inclusive digital participation for citizens, regardless of\ntheir linguistic background. Many government portals now use Bhashini’s\ncapabilities to provide real-time voice translation and multilingual support in citizen\nservice centers, public helplines, and digital grievance redressal mechanisms.\nCompanies across e-commerce, banking, and customer service have begun\nintegrating Bhashini to offer seamless voice-based assistance, allowing users to\ninteract with services in their native languages.\nExpanding reach: The continuous improvement of speech-to-text, text-to-\nspeech, and live translation models will further accelerate digital inclusion\nefforts, making Bhashini a cornerstone of the nation’s public digital infrastructure.",
    "27": "One of AI4Bharat’s earliest and most influential applications is the Supreme Court\nVidhik Anuvaad Software (SUVAS), which translates legal judgments into multiple\nIndian languages. What began as an experimental initiative has now become a\ncritical pillar of India’s judicial transparency.\nCurrent implementation: The Supreme Court has already translated over 31,000\nrulings into regional languages, with Hindi (22,396 translations), Punjabi (3,572),\nKannada (1,899), Tamil (1,172), and Gujarati (1,112) leading in volume.\nImpact: SUVAS is removing linguistic barriers in legal proceedings, enabling\ncitizens, lawyers, and policymakers to access Supreme Court judgments in their\nnative languages. This ensures greater legal process and more\ninformed decision-making at all levels.\nChallenges & solutions: While translation accuracy remains a challenge due to the\nlack of standardized legal terminology across languages, efforts are underway to\ndevelop a Common Core Vocabulary for all Indian languages. AI-driven\nenhancements continue to refine contextual accuracy, ensuring that translated\njudgments maintain legal nuance and clarity.",
    "28": "Assisted Language and Numeracy\nLearning (ALL & AXL)\nAI4Bharat is pioneering equitable education access through Assisted Language\nLearning (ALL) and Assisted Numeracy Learning (AXL), deployed in partnership\nwith the Tamil Nadu government and the EkStep Foundation. These programs are\nreshaping how students struggling with literacy and numeracy receive\npersonalized support.\nCurrent implementation: AI-powered reading support and voice-enabled\nchatbots provide customized learning experiences tailored to each student’s needs.\nImpact: The AI acts as an empathetic tutor, guiding remedial learners through\nchallenges without the pressure of traditional assessments. Students progress at\ntheir own pace, gaining confidence in their skills and bridging fundamental gaps in\neducation.\nKey feature: The AI’s ability to understand regional linguistic patterns ensures\nstudents from diverse backgrounds receive culturally relevant support, making\nlearning more natural and engaging.",
    "29": "Sarvam AI’s Generative Language Solutions\nSarvam AI, one of India’s leading AI startups, is using AI4Bharat’s datasets to\ndevelop full-stack generative AI models that cater to population-scale\napplications. The startup is setting a new benchmark for multilingual AI\ndeployment in Indian enterprises.\nCurrent implementation: Sarvam AI’s LLMs are powering customer service,\ncreating full-stack generative AI content generation, and automation in local languages.\nImpact: Businesses can now interact with millions of customers in their native\nlanguage, creating improved user engagement, market expansion, and\nFuture potential: As AI adoption grows, Sarvam’s models are poised to play a\npivotal role in India’s digital economy, enabling seamless cross-lingual\ncommunication across industries.",
    "30": "Kisan e-Mitra AI Chatbot\nThe Kisan e-Mitra chatbot, built on AI4Bharat’s technology, is a 24/7 AI-powered virtual assistant designed to empower farmers with localized agricultural knowledge.\n\nCurrent implementation: Farmers can inquire about government schemes, track application statuses, and resolve financial queries in their preferred language.\nImpact: With over 6.5 million farmers benefiting from real-time assistance, language barriers that once hindered agricultural support are now disappearing.\nSeamless financial inclusion: Under the PM-KISAN scheme, AI-driven facial authentication allows farmers to complete e-KYC verification without OTPs or biometrics, streamlining access to direct benefit transfers.\n\n“The Government of India had a very forward-looking view on AI – long before generative AI and ChatGPT became mainstream. They saw AI not as a luxury, but as essential public infrastructure. The launch of Bhashini turned that vision into reality, and now with initiatives like Kisan e-Mitra and Jadui Pitara leveraging AI, India is setting an example for how AI can drive national-scale digital inclusion.”\nShankar Maruwada, CEO of EkStep Foundation",
    "31": "e-Jaadui Pitara\nDeveloped by NCERT under the Ministry of Education, e-Jaadui Pitara is an AI-driven interactive learning app designed to engage young children (ages 3-8) with digital storytelling and personalized educational tools.\n\nCurrent implementation: The app includes animated stories, interactive learning modules, and AI-powered chatbots that provide parents and teachers with on-demand support.\nImpact: By integrating AI-driven multilingual learning tools, the app fosters early childhood education in vernacular languages, making learning more inclusive and engaging.\nAI-powered IVRS: A toll-free interactive voice response system (IVRS) enables children to listen to stories and songs in their preferred language, broadening access to engaging educational content.\n\n",
    "32": "NPCI’s Voice-Enabled UPI Payments\nIndia’s National Payments Corporation of India (NPCI) has embraced voice-assisted AI technology, allowing seamless UPI transactions via voice commands.\n\nCurrent implementation: The app enables voice navigation users to access UPI apps, authenticate transactions, and make payments entirely through voice commands.\nImpact: The feature serves digitally underserved populations, making cashless transactions more accessible to impaired users, and those unfamiliar with smartphone interfaces.\nExpanding reach: This breakthrough extends UPI’s accessibility to feature phones and IoT devices, significantly increasing India’s financial inclusion footprint.\n\n“AI has two costs: training and inference. If training costs get passed down to the user, AI services become unaffordable. That’s where open-source efforts like AI4Bharat come in. By taking the availability of large-scale AI datasets, interdisciplinary research institutions and innovators.\n\nMitesh Khapra, Head of AI4Bharat",
    "33": "INDIA’S ACADEMIC ECOSYSTEM AND ITS CONTRIBUTION TO OPEN TECHNOLOGY\nIndia is now emerging as a center for AI research, innovation, and open-source development, with universities and research institute playing a crucial role in shaping cutting-edge AI solutions.\n\nThis approach is making India an attractive destination for PhD research, offering students the opportunity to work on real-world AI infrastructure projects rather than just academic experiments.\n\nBuilding AI and Open-Source Technology in India\nA defining aspect of India’s AI research ecosystem is its commitment to open-source technology. Unlike proprietary models developed elsewhere, Indian researchers are ensuring that AI resources remain public, accessible, and adaptable for businesses, startups, and researchers.\n\nThis shift is positioning India as a key player in global AI infrastructure rather than just a consumer of technology.",
    "34": "We do not know of any other example where an idea and scaled it to impact hundreds of millions of citizens through extensive collaboration with academic institutions, state governments, and philanthropies. This is not just about AI—it’s about creating public infrastructure that fuels innovation across sectors.\n\nIndia as a Competitive Destination for AI Research\nWith its expanding research ecosystem and strong institutional support, India is becoming as attractive as any leading global university for AI and PhD studies.\nResearchers now have access to:\nNational-scale AI projects with direct real-world applications\nGovernment-backed projects\nCollaborative research opportunities with industry and academia\n\nThis environment is attracting top AI talent, reinforcing India’s position as a leader in applied AI research and open-source innovation. By ensuring that academic contributions lead to scalable, real-world solutions, India is strengthening its role in shaping the future of AI globally.",
    "35": "CREATING A GLOBAL TEMPLATE WITH AI4X\nThe success of AI4Bharat has been made possible through collaboration between government, academia, industry, and key ecosystem partners.\nFrom the outset, stakeholders such as EkStep Foundation, COSS, Google, and Meta have played a pivotal role in funding, supporting, and enabling the development of open-source AI for Indian languages.\nWith the MeitY leading the effort through the Bhashini project, AI4Bharat has evolved into a critical part of India’s Digital Public Infrastructure.\nThis initiative has helped advance speech recognition, machine translation, and text-to-speech AI models, and has also laid the groundwork for how open-source AI can be integrated into public services, governance, and accessibility solutions.\n\n“The Hindi that you speak in Lucknow is not the same as the Hindi that you speak in Haryana or the Hindi that you speak in Madhya Pradesh or Bihar. There are local nuances associated with it. And very often when people talk, they don’t talk in just one language. There will be words of Urdu, words of English, words of Telugu if you go to Hyderabad. If AI doesn’t understand this, it won’t serve real users effectively.\"\n\nAbhishek Singh\nAdditional Secretary, Ministry of Electronics and Information Technology",
    "36": "The model that has worked for India is now being adapted for other multilingual nations. AI4Bharat’s open-source frameworks, data collection methodologies, and scalable AI models are being extended to other regions where similar linguistic and technological challenges exist.\nIn parts of Africa, where multiple indigenous languages lack high-quality AI models, AI4Bharat’s data collection and model training approach provides a roadmap for building publicly accessible AI solutions.\nIn Singapore, the focus is on using AI for multilingual governance and public sector applications, ensuring that digital services are more inclusive.\nThis transition from AI4Bharat to AI4X marks a broader vision for AI as a global public good, where AI technology is built in an open, transparent, and collaborative manner rather than being controlled by a few corporations.\nBy scaling this approach internationally, India is setting a new global standard for AI development, proving that open AI models can drive economic, social, and governance-related advancements.\nThe impact of digital public goods and digital public infrastructure in India has shown that AI-driven language solutions do not have to be locked behind paywalls or corporate ownership. Instead, they can be developed as shared global assets, benefiting nations that face similar challenges in linguistic accessibility, governance, and digital transformation.",
    "37": "LOOKING AHEAD\nThe next phase of AI development in India must be structured around accessibility, inclusion, and ethical deployment. AI4Bharat has demonstrated that building AI for a linguistically diverse nation requires not only technical advancements but also a commitment to fairness, transparency, and public participation.\nThe focus now is on expanding this work to ensure that AI-driven solutions reach all communities, particularly those that have been historically underserved by technology.\nIndia’s experience with Aadhaar and UPI has shown that once technology becomes affordable and widely accessible, adoption increases rapidly. AI must follow the same trajectory. The country’s existing digital public infrastructure provides a strong foundation for scaling AI-powered solutions, particularly in governance, financial services, healthcare, and education.\nIntegrating AI models into these platforms will make digital services more linguistically inclusive and functionally accessible, ensuring that users can interact with government systems, financial tools, and online resources in their preferred language.",
    "38": "Speech recognition, machine translation, and text-to-speech technologies will be key to making these services more effective. As AI4Bharat continues refining these models, the emphasis will remain on accuracy, efficiency, and real-world applicability.\nThis includes ensuring that AI can handle dialectal variations, informal speech, and regional linguistic nuances without loss of meaning or reliability.\nThe success of AI-driven language models depends not only on the sophistication of the technology but also on how effectively they are integrated into daily life. Ensuring that digital services, financial tools, educational resources, and governance platforms are accessible in multiple languages will be a key measure of impact.\nAI4Bharat has created a strong foundation for Indian language AI, but long-term success will depend on sustained investment, responsible data collection, and a focus on public good.",
    "39": "ACKNOWLEDGEMENTS\nThe success of AI4Bharat has been made possible through the contributions and support of numerous individuals and organizations. We wish to express our sincere gratitude to all who have been part of this journey.\nWe thank the leadership at the Ministry of Electronics and Information Technology (MeitY), particularly Mr. Ajay Sawhney, former Secretary, for making us a part of the Bhashini mission, and Mr. Amit Agrawal, former Secretary, for his invaluable guidance during his tenure leading the initiative.\nOur appreciation extends to Mr. S. Krishnan, Secretary, MeitY, and Mr. Abhishek Singh for their continued support and encouragement.\nThe Bhashini mission’s success owes much to Ms. Kavita Bhatia, Group Coordinator, for her guidance, Mr. Amitabh Nag, CEO, for the partnership with DIBD that helped bring the technology to the ground, and Mr. Vijay Kumar, Scientist F, for his valuable inputs, discussions, and administrative support throughout the project.\nWe are deeply indebted to our academic mentors: Prof. Rajeev Sangal for steering the Bhashini mission; Prof. Pushpak Bhattacharyya for his continued guidance; and Prof. Hema Murthy and Prof. V. Kamakoti, Director IIT Madras, and Prof. B. Ravindran, Head of Wadhwani School of AI, for their administrative support and encouragement.\nThis work would not have been possible without the trust and backing of Mr. Nandan Nilekani and Ms. Rohini Nilekani, who believed in our cause and became the driving force behind our efforts.\nWe are grateful to Mr. Shankar Maruwada and Mr. Jagadish Babu for their guidance in bringing our technology to the ground for social impact, and to Mr. Tanuj Bhojwani for championing AI4Bharat’s work.\nWe acknowledge the support of our organizational partners: People+AI for helping us stay grounded and ensuring our work aligns with real needs; Mr. Anand Raman and Microsoft for generous grant support and collaborations, Google for providing travel grants towards improving AI4Bharat students, and the Gates Foundation for their grants towards scholarships to AI4Bharat technology.\nWe thank the team that helped compile this milestone report to share the AI4Bharat journey with the public: David Menezes, Akash Tandon, and Sonia Rebecca Benaraz."
  },
  "skipped_pages": [
    15,
    16,
    17,
    18,
    19
  ]
}